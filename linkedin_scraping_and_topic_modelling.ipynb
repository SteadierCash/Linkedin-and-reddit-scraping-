{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "description_df = pd.DataFrame(columns = ['Job Description', 'Job Link'])\n",
    "job_df = pd.DataFrame(columns = ['Company', 'Job Title', 'Job Link'])\n",
    "\n",
    "def linkedin_scraper(webpage, page_number):\n",
    "    next_page = webpage + str(page_number)\n",
    "    response = requests.get(str(next_page))\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "    jobs = soup.find_all('div', class_='base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
    "    job_data = []\n",
    "    for job in jobs:\n",
    "        job_title = job.find('h3', class_='base-search-card__title').text.strip()\n",
    "        job_link = job.find('a', class_='base-card__full-link')['href']\n",
    "        job_company = job.find('a', class_='hidden-nested-link').text.strip()\n",
    "\n",
    "        job_data.append({'Company': job_company, 'Job Title': job_title, 'Job Link': job_link})\n",
    "    global job_df\n",
    "    job_df = pd.concat([job_df, pd.DataFrame(job_data)], ignore_index=True)\n",
    "    print('Data updated')\n",
    "\n",
    "def get_description(webpage, page_number):\n",
    "    next_page = webpage + str(page_number)\n",
    "    response = requests.get(str(next_page))\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "    url_deep = []\n",
    "    description_data = []\n",
    "\n",
    "    for a in soup.find_all('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]',href=True):\n",
    "        url_deep.append(a['href'])\n",
    "\n",
    "    for u in url_deep:\n",
    "        # Make a request to the second page\n",
    "        response_deep = requests.get(u)\n",
    "\n",
    "        # Find all description elements\n",
    "        sub_soup = BeautifulSoup(response_deep.content, features=\"lxml\")\n",
    "        descr = sub_soup.find(\"div\", {\"class\": \"description__text description__text--rich\"})\n",
    "\n",
    "        if descr is not None:\n",
    "            description_data.append({'Job Description': descr.text, 'Job Link': u})\n",
    "        else:\n",
    "            print(f\"Job description not found for {u}\")\n",
    "\n",
    "    global description_df\n",
    "    description_df = pd.concat([description_df, pd.DataFrame(description_data)], ignore_index=True)\n",
    "    return description_df \n",
    "\n",
    "\n",
    "def start_scraping(webpage, page_number, max_pages):\n",
    "    job_df = pd.DataFrame(columns = ['Company', 'Job Title', 'Job Link'])\n",
    "    job_df = linkedin_scraper(webpage, page_number)\n",
    "    description_df = pd.DataFrame(columns = ['Job Description', 'Job Link'])\n",
    "    description_df = get_description(webpage, page_number)\n",
    "    if page_number == 0:\n",
    "        all_jobs = job_df\n",
    "        all_descriptions = description_df\n",
    "    else:\n",
    "        try:\n",
    "            all_jobs\n",
    "        except NameError:\n",
    "            all_jobs = job_df\n",
    "        else:\n",
    "            all_jobs = pd.concat([all_jobs, job_df], ignore_index=True)\n",
    "        try:\n",
    "            all_descriptions\n",
    "        except NameError:\n",
    "            all_descriptions = description_df\n",
    "        else:\n",
    "            all_descriptions = pd.concat([all_descriptions, description_df], ignore_index=True)\n",
    "    if page_number < max_pages:\n",
    "        start_scraping(webpage, page_number + 25, max_pages)\n",
    "    else:\n",
    "        print('File closed')\n",
    "\n",
    "start_scraping('https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Product%20Management&location=San%20Francisco%20Bay%20Area&geoId=90000084&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0&start=', 0, 1000)       \n",
    "\n",
    "def join_dataframes(job_df, description_df):\n",
    "\n",
    "    description_df = description_df.drop_duplicates().reset_index().drop(columns = 'index')\n",
    "    merged_df = job_df.merge(description_df, left_index=True, right_index=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "merged_df = join_dataframes(job_df, description_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having merged_df it would be great to now start doing somethign with the descriptions themselves; not just in combination with our reddit scraping\n",
    "\n",
    "# let's drop unnecessary job link column\n",
    "\n",
    "merged_df.drop(columns = 'Job Link_y', inplace = True)\n",
    "\n",
    "# now let's start cleaning our description\n",
    "\n",
    "def clean_text(df):\n",
    "\n",
    "    df['Preprocessed Descriptions'] = \"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # Get the description text from the current row\n",
    "        description = row['Job Description']\n",
    "\n",
    "        # Remove URLs\n",
    "        description = re.sub(r'http\\S+', '', description)\n",
    "\n",
    "        # remove punctuation\n",
    "        description = re.sub(r'[^\\w\\s\\d]', ' ', description)\n",
    "\n",
    "        # Remove non-ASCII characters\n",
    "        description = description.encode('ascii', 'ignore').decode()\n",
    "\n",
    "        # Remove phrases that are not impactful to the analysis\n",
    "        description = re.sub(r'Show less|Show more|Description|Company description', '', description)\n",
    "\n",
    "        # Normalize currency symbols\n",
    "        description = re.sub(r\"(\\d+(?:\\.\\d+)?)(\\s?)(\\$|€|USD|EUR)(\\s?)\", r\"\\1 \\3\", description)\n",
    "        description = re.sub(r\"\\b(\\d+(?:\\.\\d+)?) ?(\\$|USD|EUR|€)\\b\", r\"\\1 \\2\", description)\n",
    "        description = re.sub(r\"(\\$|USD)\\s*(\\d+(?:\\.\\d+)?)\", r\"\\2 \\1\", description)\n",
    "        description = re.sub(r\"(\\d+(?:\\.\\d+)?) ?(USD|EUR|€)\", r\"\\1 \\2\", description)\n",
    "        description = re.sub(r\"(USD|EUR|€)\\s*(\\d+(?:\\.\\d+)?)\", r\"\\2 \\1\", description)\n",
    "        description = re.sub(r\"\\b(\\$|USD|EUR|€)\\b\", \"USD\", description)\n",
    "\n",
    "        # Separate words that got entangled together\n",
    "        description = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', description)\n",
    "\n",
    "        # replace double space\n",
    "\n",
    "        while \"  \" in description: \n",
    "            description = description.replace(\"  \", \" \")\n",
    "\n",
    "        # Update the preprocessed description in the dataframe\n",
    "        df.at[index, 'Preprocessed Descriptions'] = description\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "df_cleaned = clean_text(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename the job link column and drop unnecessary job description\n",
    "df_cleaned.rename(columns = {'Job Link_x': 'Job Link'}, inplace = True)\n",
    "# df_cleaned.drop(columns = 'Job Description', inplace = True)\n",
    "\n",
    "# lets also remove stopwords \n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_cleaned['Preprocessed Descriptions'] = df_cleaned['Preprocessed Descriptions'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load your preprocessed job description data from your DataFrame\n",
    "descriptions = df_cleaned['Preprocessed Descriptions'].tolist()\n",
    "\n",
    "tokenized_descriptions = []\n",
    "\n",
    "for description in descriptions:\n",
    "    tokens = word_tokenize(description)\n",
    "    tokenized_descriptions.append(tokens)\n",
    "\n",
    "# Convert the preprocessed descriptions to a document-term matrix\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "doc_term_matrix = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "# Fit a topic model to the document-term matrix\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "# Evaluate the topic model using perplexity score\n",
    "print(\"Perplexity score:\", lda.perplexity(doc_term_matrix))\n",
    "\n",
    "\n",
    "# Interpret the results of the topic model\n",
    "dictionary = Dictionary(tokenized_descriptions) # create the dictionary object\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_descriptions] # create the corpus object\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, random_state=42)\n",
    "topics = lda_model.show_topics(num_topics=10, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while the lda model is in progress, i'm also gonna build some clusters using kmeans and search for single topics within the \n",
    "# descriptions; it is not gonna be sophisticated, but may be helpful to gain a high level view\n",
    "\n",
    "\n",
    "df_cleaned.rename(columns = {'Preprocessed Descriptions':'Descriptions'}, inplace = True)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a TF-IDF vectorizer object\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english', ngram_range = (1,3))\n",
    "\n",
    "# Fit the vectorizer to the preprocessed descriptions\n",
    "tfidf = vectorizer.fit_transform(df_cleaned['Descriptions'])\n",
    "\n",
    "# Get the feature names (i.e., the words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the sparse matrix to a pandas DataFrame for easier manipulation\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a K-means clustering object with k=5 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit the K-means object to the TF-IDF matrix\n",
    "kmeans.fit(tfidf_df)\n",
    "\n",
    "# Add the predicted cluster labels to the original DataFrame\n",
    "df_cleaned['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce the dimensionality of the TF-IDF matrix to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "tfidf_2d = pca.fit_transform(tfidf.toarray())\n",
    "\n",
    "# Plot the data points with different colors for each cluster\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['red', 'green', 'blue', 'purple', 'orange', 'gray', 'black', 'pink', 'brown', 'cyan']\n",
    "for i in range(kmeans.n_clusters):\n",
    "    plt.scatter(tfidf_2d[kmeans.labels_ == i, 0], tfidf_2d[kmeans.labels_ == i, 1], c=colors[i], label='Cluster {}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('Clusters of Job Descriptions')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cluster centers in the TF-IDF space\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# For each cluster, get the top 10 features\n",
    "n_top_features = 10\n",
    "for i, center in enumerate(cluster_centers):\n",
    "    print(f\"\\nTop {n_top_features} words for cluster {i}:\")\n",
    "    top_features_idx = center.argsort()[::-1][:n_top_features]\n",
    "    top_features = [feature_names[idx] for idx in top_features_idx]\n",
    "    print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'm going to try to build the LDA model once again a bit differently\n",
    "# the change in approach will mostly include change in data preprocessing\n",
    "\n",
    "job_descriptions = join_dataframes(job_df, description_df)\n",
    "job_descriptions.drop(columns = 'Job Link_y', inplace = True )\n",
    "\n",
    "#gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "  \n",
    "#spacy\n",
    "import spacy\n",
    "\n",
    "#vis\n",
    "import pyLDAvis \n",
    "import pyLDAvis.gensim\n",
    "\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start preprocessing the data\n",
    "\n",
    "def lemmatization(texts, allowed_tags = ['NOUN','ADJ','VERB','ADV']):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        if not isinstance(text, str):\n",
    "            print(f\"Found non-string element: {text}\")\n",
    "        else:\n",
    "            tokens = nlp(text)\n",
    "            lemmas = [token.lemma_ for token in tokens if token.pos_ in allowed_tags]\n",
    "            texts_out.append(\" \".join(lemmas))\n",
    "    return texts_out\n",
    "\n",
    "lemmatized_texts = lemmatization(job_descriptions['Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text)\n",
    "        final.append(new)\n",
    "    return final\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the words and producing tuples (index, frequency)\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for text in data_words:\n",
    "    new = id2word.doc2bow(text)\n",
    "    corpus.append(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model \n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                            id2word = id2word,\n",
    "                                            num_topics = 30,\n",
    "                                            random_state = 50,\n",
    "                                            update_every = 1,\n",
    "                                            chunksize = 100,\n",
    "                                            passes = 10,\n",
    "                                            alpha = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the otuput\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds = 'mmds', R = 30)\n",
    "vis\n",
    "\n",
    "# after visualizing for the 1st time I can see that 1) I used way too high topics value and 2) there are common words like 'more', 'lead' etc. which\n",
    "# are of no interest to me and I should think about how to remove those "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i am gonna create bigrams/ trigrams as well as remove frequent words that do not bring much to my analysis\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# create bigram phrases\n",
    "bigram_phrases = Phrases(data_words, min_count=5, threshold=80)\n",
    "\n",
    "# transform the corpus using the bigram phrases\n",
    "data_bigrams = [bigram_phrases[doc] for doc in data_words]\n",
    "\n",
    "# create trigram phrases\n",
    "trigram_phrases = Phrases(data_bigrams, min_count=5, threshold=80)\n",
    "\n",
    "# transform the corpus using the trigram phrases\n",
    "data_trigrams = [trigram_phrases[bigram_doc] for bigram_doc in data_bigrams]\n",
    "\n",
    "# create a Phraser object for the trigram phrases (optional, but recommended for faster processing)\n",
    "trigram_phraser = Phraser(trigram_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's remove the frequent unnecessary rows\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# Create a dictionary of the trigrams in the data\n",
    "id2word = corpora.Dictionary(data_trigrams)\n",
    "\n",
    "# Convert the data to a bag-of-words corpus\n",
    "texts = data_trigrams \n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Compute the TF-IDF scores for the corpus\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "# Define a threshold for low-value words\n",
    "low_value = 0.03\n",
    "\n",
    "# Initialize lists for storing low-value words and missing words\n",
    "words = []\n",
    "words_missing_in_tfidf = []\n",
    "\n",
    "# Loop over each document in the corpus\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    \n",
    "    # Initialize a list for storing low-value words\n",
    "    low_value_words = []\n",
    "    \n",
    "    # Get the IDs of words with nonzero TF-IDF scores\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    \n",
    "    # Get the IDs of all words in the document\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    \n",
    "    # Find all words with a TF-IDF score below the threshold\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    \n",
    "    # Add low-value words and missing words to the list of words to be dropped\n",
    "    drops = low_value_words + words_missing_in_tfidf\n",
    "    \n",
    "    # Add dropped words to the list of words\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    \n",
    "    # Find all words that are missing from the TF-IDF model\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "    \n",
    "    # Remove all low-value and missing words from the document\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]  \n",
    "    \n",
    "    # Replace the original document with the cleaned-up version\n",
    "    corpus[i] = new_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                            id2word = id2word,\n",
    "                                            num_topics = 20,\n",
    "                                            random_state = 50,\n",
    "                                            update_every = 1,\n",
    "                                            chunksize = 100,\n",
    "                                            passes = 10,\n",
    "                                            alpha = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize it\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds = 'mmds', R = 30)\n",
    "vis\n",
    "\n",
    "#looks much better now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also do lda model with word embeddings insteaf of bag od words\n",
    "\n",
    "# generally, word emebeddings can work better when the data has complex relationships between words: For example, word embeddings can be useful \n",
    "# for natural language processing tasks where the meaning of a word depends on its context within a sentence or document.\n",
    "# let's see if there's sense in using it here\n",
    "\n",
    "corpus = [\" \".join(doc) for doc in texts]\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# Build a word2vec model using your corpus\n",
    "model_w2v = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Build a gensim dictionary using your corpus\n",
    "processed_corpus = [doc.split() for doc in corpus] # split the string into tokens\n",
    "dictionary = Dictionary(processed_corpus)\n",
    "\n",
    "# Convert the corpus into bag-of-words format\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_corpus]\n",
    "\n",
    "# Train an LDA model on the bag-of-words corpus\n",
    "num_topics = 10 # change this value to set the desired number of topics\n",
    "lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Print the topics and their top terms\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\nWords: {topic}\\n')\n",
    "\n",
    "\n",
    "# after several tries i don't think it makes sense this case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Link_x</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Link_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Director Product Management - Feed</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/director-pr...</td>\n",
       "      <td>\\n\\n\\nCompany DescriptionLinkedIn was built to...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/director-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vice President - Product Strategy, Chief of Staff</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/vice-presid...</td>\n",
       "      <td>\\n\\n\\nCompany DescriptionFreshworks makes it f...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/vice-presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Director, Product Management, Labs</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-dire...</td>\n",
       "      <td>\\n\\n\\n        Applications will be accepted th...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Director of Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/director-of...</td>\n",
       "      <td>\\n\\n\\nAbout Lyra HealthLyra is transforming me...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/director-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global Head of Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-head...</td>\n",
       "      <td>\\n\\n\\n        EA SPORTS is one of the most ico...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Head of Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-head...</td>\n",
       "      <td>\\n\\n\\n        EA SPORTS is one of the most ico...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Head of Product</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "      <td>\\n\\n\\nAbout FarmWise:At FarmWise, we harness t...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Head of Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "      <td>\\n\\n\\nWell-funded series A startup looking to ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Head of Business Operations - Games Operations</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-bus...</td>\n",
       "      <td>\\n\\n\\n        Netflix is looking for an experi...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product Owner, Data and Analytics - Remote</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-own...</td>\n",
       "      <td>\\n\\n\\n        PayNearMe, a service of Handle F...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-own...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manager of Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/manager-of-...</td>\n",
       "      <td>\\n\\n\\nManager of Product Management, or Direct...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/manager-of-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-ma...</td>\n",
       "      <td>\\n\\n\\nBusiness Manager –The Business Manager i...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Product Owner</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-own...</td>\n",
       "      <td>\\n\\n\\nSummary Imagine what you could do here. ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/operations-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iPhone Operations Program Management Opportuni...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/iphone-oper...</td>\n",
       "      <td>\\n\\n\\nAs our Product Owner, you will build pro...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-own...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Product Support Operations Manager, Games</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-sup...</td>\n",
       "      <td>\\n\\n\\nSummary Imagine what you could do here. ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/iphone-oper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Worldwide Supply Demand Product Planner</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/worldwide-s...</td>\n",
       "      <td>\\n\\n\\n        At Netflix, we are shaping the f...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Global Supply Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\nSummary Imagine what you could do here. ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/worldwide-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Product Operation Manager Lead, TikTok E-commerce</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ope...</td>\n",
       "      <td>\\n\\n\\nSummary Imagine what you could do here. ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ana...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Product Manager, TikTok Ads Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-man...</td>\n",
       "      <td>\\n\\n\\n        At PayPal (NASDAQ: PYPL), we bel...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Global Manufacturing Partner Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-manu...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TikTok Commerce - Customer Success Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tiktok-comm...</td>\n",
       "      <td>\\n\\n\\n        Note: By applying to this positi...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Group Manager, Process Excellence &amp; Continuous...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/group-manag...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tiktok-comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TikTok Commerce Product Manager - Agency Partners</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tiktok-comm...</td>\n",
       "      <td>\\n\\n\\nWhat To ExpectWe are looking for a proce...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/group-manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Global Supply Manager, Solar</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tiktok-comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ana...</td>\n",
       "      <td>\\n\\n\\n        At PayPal (NASDAQ: PYPL), we bel...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sr Manager, Global Marketing</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-manager-...</td>\n",
       "      <td>\\n\\n\\nSr Manager, Global Marketing Benefit Cos...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-manager-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manager, Strategic Partnerships</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/manager-str...</td>\n",
       "      <td>\\n\\n\\n        The Senior Product Manager, Walm...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Head of Product Manager - Data, TikTok E-commerce</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "      <td>\\n\\n\\n        Netflix is revolutionizing enter...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/manager-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Supply Operations Analyst</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-oper...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NPI Fulfillment Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/npi-fulfill...</td>\n",
       "      <td>\\n\\n\\nWhat To ExpectWe are looking for a highl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-oper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Global Supply Manager, Fleet Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\nSummary The people here at Apple don’t j...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/npi-fulfill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Associate Director, Product Management</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "      <td>\\n\\n\\nWhat To ExpectWe are looking for a highl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Operations Manager, User Growth</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/operations-...</td>\n",
       "      <td>\\n\\n\\nAbout MOLOCOMoloco's goal is to make the...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/head-of-glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business Operations Lead</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-op...</td>\n",
       "      <td>\\n\\n\\nAbout The CompanyOur purpose at Talis Bi...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Product Lead - Business Integrity</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-lea...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/operations-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Supply Chain Program Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-chai...</td>\n",
       "      <td>\\n\\n\\nBE PART OF BUILDING THE FUTURE.What do N...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Staff Product Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-produ...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Global Supply Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\nResponsibilities TikTok is the leading d...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Product Information Analyst</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-inf...</td>\n",
       "      <td>\\n\\n\\nCompany DescriptionFreshworks makes it f...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Continuous Improvement Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/continuous-...</td>\n",
       "      <td>\\n\\n\\nWhat To ExpectWe are looking for a highl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Supply Chain Program Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-chai...</td>\n",
       "      <td>\\n\\n\\nAbout the RoleThis position reports to t...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>User Experience Product Manager Lead, After-Sa...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/user-experi...</td>\n",
       "      <td>\\n\\n\\nRedzone is hiring CI Coaches (Full-Time ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/continuous-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Customer Success Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/customer-su...</td>\n",
       "      <td>\\n\\n\\nHyve Solutions is a leader in the data c...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/supply-chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>International Business Development Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internation...</td>\n",
       "      <td>\\n\\n\\nResponsibilities Company Overview:TikTok...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/user-experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Staff Product Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-produ...</td>\n",
       "      <td>\\n\\n\\nABOUT JIVOXJivox is the market leader in...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/customer-su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Product Manager Leader - Brand Ads</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-man...</td>\n",
       "      <td>\\n\\n\\nAbout the Company:BioGenex designs, deve...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Global Supply Manager</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\nAbout The RoleWe are seeking a Staff Pro...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Product/Project Management Grad</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-pro...</td>\n",
       "      <td>\\n\\n\\nWhat To ExpectWe are looking for a highl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Global Supply Analyst - Passives</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/global-supp...</td>\n",
       "      <td>\\n\\n\\n        This role has been designated as...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                  Director Product Management - Feed   \n",
       "1   Vice President - Product Strategy, Chief of Staff   \n",
       "2           Senior Director, Product Management, Labs   \n",
       "3                      Director of Product Management   \n",
       "4                   Global Head of Product Management   \n",
       "5                   Global Head of Product Management   \n",
       "6                                     Head of Product   \n",
       "7                          Head of Product Management   \n",
       "8      Head of Business Operations - Games Operations   \n",
       "9          Product Owner, Data and Analytics - Remote   \n",
       "10                      Manager of Product Management   \n",
       "11                                   Business Manager   \n",
       "12                                      Product Owner   \n",
       "13  iPhone Operations Program Management Opportuni...   \n",
       "14          Product Support Operations Manager, Games   \n",
       "15            Worldwide Supply Demand Product Planner   \n",
       "16                              Global Supply Manager   \n",
       "17  Product Operation Manager Lead, TikTok E-commerce   \n",
       "18                                    Product Analyst   \n",
       "19                Product Manager, TikTok Ads Manager   \n",
       "20               Global Manufacturing Partner Manager   \n",
       "21         TikTok Commerce - Customer Success Manager   \n",
       "22  Group Manager, Process Excellence & Continuous...   \n",
       "23  TikTok Commerce Product Manager - Agency Partners   \n",
       "24                       Global Supply Manager, Solar   \n",
       "25                                    Product Analyst   \n",
       "26                       Sr Manager, Global Marketing   \n",
       "27                    Manager, Strategic Partnerships   \n",
       "28  Head of Product Manager - Data, TikTok E-commerce   \n",
       "29                          Supply Operations Analyst   \n",
       "30                            NPI Fulfillment Manager   \n",
       "31            Global Supply Manager, Fleet Management   \n",
       "32             Associate Director, Product Management   \n",
       "33                    Operations Manager, User Growth   \n",
       "34                           Business Operations Lead   \n",
       "35                  Product Lead - Business Integrity   \n",
       "36                       Supply Chain Program Manager   \n",
       "37                              Staff Product Manager   \n",
       "38                              Global Supply Manager   \n",
       "39                        Product Information Analyst   \n",
       "40                     Continuous Improvement Manager   \n",
       "41                       Supply Chain Program Manager   \n",
       "42  User Experience Product Manager Lead, After-Sa...   \n",
       "43                           Customer Success Manager   \n",
       "44         International Business Development Manager   \n",
       "45                              Staff Product Manager   \n",
       "46                 Product Manager Leader - Brand Ads   \n",
       "47                              Global Supply Manager   \n",
       "48                    Product/Project Management Grad   \n",
       "49                   Global Supply Analyst - Passives   \n",
       "\n",
       "                                           Job Link_x  \\\n",
       "0   https://www.linkedin.com/jobs/view/director-pr...   \n",
       "1   https://www.linkedin.com/jobs/view/vice-presid...   \n",
       "2   https://www.linkedin.com/jobs/view/senior-dire...   \n",
       "3   https://www.linkedin.com/jobs/view/director-of...   \n",
       "4   https://www.linkedin.com/jobs/view/global-head...   \n",
       "5   https://www.linkedin.com/jobs/view/global-head...   \n",
       "6   https://www.linkedin.com/jobs/view/head-of-pro...   \n",
       "7   https://www.linkedin.com/jobs/view/head-of-pro...   \n",
       "8   https://www.linkedin.com/jobs/view/head-of-bus...   \n",
       "9   https://www.linkedin.com/jobs/view/product-own...   \n",
       "10  https://www.linkedin.com/jobs/view/manager-of-...   \n",
       "11  https://www.linkedin.com/jobs/view/business-ma...   \n",
       "12  https://www.linkedin.com/jobs/view/product-own...   \n",
       "13  https://www.linkedin.com/jobs/view/iphone-oper...   \n",
       "14  https://www.linkedin.com/jobs/view/product-sup...   \n",
       "15  https://www.linkedin.com/jobs/view/worldwide-s...   \n",
       "16  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "17  https://www.linkedin.com/jobs/view/product-ope...   \n",
       "18  https://www.linkedin.com/jobs/view/product-ana...   \n",
       "19  https://www.linkedin.com/jobs/view/product-man...   \n",
       "20  https://www.linkedin.com/jobs/view/global-manu...   \n",
       "21  https://www.linkedin.com/jobs/view/tiktok-comm...   \n",
       "22  https://www.linkedin.com/jobs/view/group-manag...   \n",
       "23  https://www.linkedin.com/jobs/view/tiktok-comm...   \n",
       "24  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "25  https://www.linkedin.com/jobs/view/product-ana...   \n",
       "26  https://www.linkedin.com/jobs/view/sr-manager-...   \n",
       "27  https://www.linkedin.com/jobs/view/manager-str...   \n",
       "28  https://www.linkedin.com/jobs/view/head-of-pro...   \n",
       "29  https://www.linkedin.com/jobs/view/supply-oper...   \n",
       "30  https://www.linkedin.com/jobs/view/npi-fulfill...   \n",
       "31  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "32  https://www.linkedin.com/jobs/view/associate-d...   \n",
       "33  https://www.linkedin.com/jobs/view/operations-...   \n",
       "34  https://www.linkedin.com/jobs/view/business-op...   \n",
       "35  https://www.linkedin.com/jobs/view/product-lea...   \n",
       "36  https://www.linkedin.com/jobs/view/supply-chai...   \n",
       "37  https://www.linkedin.com/jobs/view/staff-produ...   \n",
       "38  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "39  https://www.linkedin.com/jobs/view/product-inf...   \n",
       "40  https://www.linkedin.com/jobs/view/continuous-...   \n",
       "41  https://www.linkedin.com/jobs/view/supply-chai...   \n",
       "42  https://www.linkedin.com/jobs/view/user-experi...   \n",
       "43  https://www.linkedin.com/jobs/view/customer-su...   \n",
       "44  https://www.linkedin.com/jobs/view/internation...   \n",
       "45  https://www.linkedin.com/jobs/view/staff-produ...   \n",
       "46  https://www.linkedin.com/jobs/view/product-man...   \n",
       "47  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "48  https://www.linkedin.com/jobs/view/product-pro...   \n",
       "49  https://www.linkedin.com/jobs/view/global-supp...   \n",
       "\n",
       "                                      Job Description  \\\n",
       "0   \\n\\n\\nCompany DescriptionLinkedIn was built to...   \n",
       "1   \\n\\n\\nCompany DescriptionFreshworks makes it f...   \n",
       "2   \\n\\n\\n        Applications will be accepted th...   \n",
       "3   \\n\\n\\nAbout Lyra HealthLyra is transforming me...   \n",
       "4   \\n\\n\\n        EA SPORTS is one of the most ico...   \n",
       "5   \\n\\n\\n        EA SPORTS is one of the most ico...   \n",
       "6   \\n\\n\\nAbout FarmWise:At FarmWise, we harness t...   \n",
       "7   \\n\\n\\nWell-funded series A startup looking to ...   \n",
       "8   \\n\\n\\n        Netflix is looking for an experi...   \n",
       "9   \\n\\n\\n        PayNearMe, a service of Handle F...   \n",
       "10  \\n\\n\\nManager of Product Management, or Direct...   \n",
       "11  \\n\\n\\nBusiness Manager –The Business Manager i...   \n",
       "12  \\n\\n\\nSummary Imagine what you could do here. ...   \n",
       "13  \\n\\n\\nAs our Product Owner, you will build pro...   \n",
       "14  \\n\\n\\nSummary Imagine what you could do here. ...   \n",
       "15  \\n\\n\\n        At Netflix, we are shaping the f...   \n",
       "16  \\n\\n\\nSummary Imagine what you could do here. ...   \n",
       "17  \\n\\n\\nSummary Imagine what you could do here. ...   \n",
       "18  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "19  \\n\\n\\n        At PayPal (NASDAQ: PYPL), we bel...   \n",
       "20  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "21  \\n\\n\\n        Note: By applying to this positi...   \n",
       "22  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "23  \\n\\n\\nWhat To ExpectWe are looking for a proce...   \n",
       "24  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "25  \\n\\n\\n        At PayPal (NASDAQ: PYPL), we bel...   \n",
       "26  \\n\\n\\nSr Manager, Global Marketing Benefit Cos...   \n",
       "27  \\n\\n\\n        The Senior Product Manager, Walm...   \n",
       "28  \\n\\n\\n        Netflix is revolutionizing enter...   \n",
       "29  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "30  \\n\\n\\nWhat To ExpectWe are looking for a highl...   \n",
       "31  \\n\\n\\nSummary The people here at Apple don’t j...   \n",
       "32  \\n\\n\\nWhat To ExpectWe are looking for a highl...   \n",
       "33  \\n\\n\\nAbout MOLOCOMoloco's goal is to make the...   \n",
       "34  \\n\\n\\nAbout The CompanyOur purpose at Talis Bi...   \n",
       "35  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "36  \\n\\n\\nBE PART OF BUILDING THE FUTURE.What do N...   \n",
       "37  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "38  \\n\\n\\nResponsibilities TikTok is the leading d...   \n",
       "39  \\n\\n\\nCompany DescriptionFreshworks makes it f...   \n",
       "40  \\n\\n\\nWhat To ExpectWe are looking for a highl...   \n",
       "41  \\n\\n\\nAbout the RoleThis position reports to t...   \n",
       "42  \\n\\n\\nRedzone is hiring CI Coaches (Full-Time ...   \n",
       "43  \\n\\n\\nHyve Solutions is a leader in the data c...   \n",
       "44  \\n\\n\\nResponsibilities Company Overview:TikTok...   \n",
       "45  \\n\\n\\nABOUT JIVOXJivox is the market leader in...   \n",
       "46  \\n\\n\\nAbout the Company:BioGenex designs, deve...   \n",
       "47  \\n\\n\\nAbout The RoleWe are seeking a Staff Pro...   \n",
       "48  \\n\\n\\nWhat To ExpectWe are looking for a highl...   \n",
       "49  \\n\\n\\n        This role has been designated as...   \n",
       "\n",
       "                                           Job Link_y  \n",
       "0   https://www.linkedin.com/jobs/view/director-pr...  \n",
       "1   https://www.linkedin.com/jobs/view/vice-presid...  \n",
       "2   https://www.linkedin.com/jobs/view/senior-dire...  \n",
       "3   https://www.linkedin.com/jobs/view/director-of...  \n",
       "4   https://www.linkedin.com/jobs/view/global-head...  \n",
       "5   https://www.linkedin.com/jobs/view/global-head...  \n",
       "6   https://www.linkedin.com/jobs/view/head-of-pro...  \n",
       "7   https://www.linkedin.com/jobs/view/head-of-pro...  \n",
       "8   https://www.linkedin.com/jobs/view/head-of-bus...  \n",
       "9   https://www.linkedin.com/jobs/view/product-own...  \n",
       "10  https://www.linkedin.com/jobs/view/manager-of-...  \n",
       "11  https://www.linkedin.com/jobs/view/business-ma...  \n",
       "12  https://www.linkedin.com/jobs/view/operations-...  \n",
       "13  https://www.linkedin.com/jobs/view/product-own...  \n",
       "14  https://www.linkedin.com/jobs/view/iphone-oper...  \n",
       "15  https://www.linkedin.com/jobs/view/product-sup...  \n",
       "16  https://www.linkedin.com/jobs/view/worldwide-s...  \n",
       "17  https://www.linkedin.com/jobs/view/global-supp...  \n",
       "18  https://www.linkedin.com/jobs/view/product-ope...  \n",
       "19  https://www.linkedin.com/jobs/view/product-ana...  \n",
       "20  https://www.linkedin.com/jobs/view/product-man...  \n",
       "21  https://www.linkedin.com/jobs/view/global-manu...  \n",
       "22  https://www.linkedin.com/jobs/view/tiktok-comm...  \n",
       "23  https://www.linkedin.com/jobs/view/group-manag...  \n",
       "24  https://www.linkedin.com/jobs/view/tiktok-comm...  \n",
       "25  https://www.linkedin.com/jobs/view/product-ana...  \n",
       "26  https://www.linkedin.com/jobs/view/sr-manager-...  \n",
       "27  https://www.linkedin.com/jobs/view/staff-produ...  \n",
       "28  https://www.linkedin.com/jobs/view/manager-str...  \n",
       "29  https://www.linkedin.com/jobs/view/head-of-pro...  \n",
       "30  https://www.linkedin.com/jobs/view/supply-oper...  \n",
       "31  https://www.linkedin.com/jobs/view/npi-fulfill...  \n",
       "32  https://www.linkedin.com/jobs/view/global-supp...  \n",
       "33  https://www.linkedin.com/jobs/view/head-of-glo...  \n",
       "34  https://www.linkedin.com/jobs/view/associate-d...  \n",
       "35  https://www.linkedin.com/jobs/view/operations-...  \n",
       "36  https://www.linkedin.com/jobs/view/business-op...  \n",
       "37  https://www.linkedin.com/jobs/view/product-lea...  \n",
       "38  https://www.linkedin.com/jobs/view/supply-chai...  \n",
       "39  https://www.linkedin.com/jobs/view/staff-produ...  \n",
       "40  https://www.linkedin.com/jobs/view/global-supp...  \n",
       "41  https://www.linkedin.com/jobs/view/product-inf...  \n",
       "42  https://www.linkedin.com/jobs/view/continuous-...  \n",
       "43  https://www.linkedin.com/jobs/view/supply-chai...  \n",
       "44  https://www.linkedin.com/jobs/view/user-experi...  \n",
       "45  https://www.linkedin.com/jobs/view/customer-su...  \n",
       "46  https://www.linkedin.com/jobs/view/internation...  \n",
       "47  https://www.linkedin.com/jobs/view/staff-produ...  \n",
       "48  https://www.linkedin.com/jobs/view/global-supp...  \n",
       "49  https://www.linkedin.com/jobs/view/product-pro...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stary kod pod deskrypcje, zostawiam na wszelki wielki\n",
    "'''description_df = pd.DataFrame(columns = ['Description', 'Job Link'])\n",
    "\n",
    "def get_description(webpage, page_number, description_df):\n",
    "    next_page = webpage + str(page_number)\n",
    "    response = requests.get(str(next_page))\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "    url_deep = []\n",
    "\n",
    "    for a in soup.find_all('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]',href=True):\n",
    "        url_deep.append(a['href'])\n",
    "\n",
    "    for u in url_deep:\n",
    "    # Make a request to the second page\n",
    "        response_deep = requests.get(u)\n",
    "\n",
    "    # Find all description elements\n",
    "        sub_soup=BeautifulSoup(response_deep.content,features=\"lxml\")\n",
    "        text1=sub_soup.findAll(\"div\", {\"class\": \"description__text description__text--rich\"})\n",
    "\n",
    "        for s in text1:\n",
    "            description = s.text\n",
    "            description_df = description_df.append({'Description': description, 'Job Link': u}, ignore_index=True)\n",
    "    return description_df        \n",
    "\n",
    "get_description('https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=data%20science&location=Stany%20Zjednoczone&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0&start=',0, description_df)'''\n",
    "\n",
    "'''import pandas as pd\n",
    "import re\n",
    "\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "description_df = pd.DataFrame(columns = ['Description'])\n",
    "\n",
    "\n",
    "url_deep = []\n",
    "for a in soup.find_all('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]',href=True):\n",
    "    url_deep.append(a['href'])\n",
    "    \n",
    "redundancy_character=['</em>','</p>','<p>','<em>','<trong>','</li>','<li>','<div class=\"description__text description__text--rich\">',\n",
    "                      '</ul>','<ul>','<u>','</u>','</div>', '<br>','</br>','<br/>','<br/>'] \n",
    "\n",
    "for u in url_deep:\n",
    "    # Make a request to the second page\n",
    "    response_deep = requests.get(u)\n",
    "\n",
    "    # Find all description elements\n",
    "    sub_soup=BeautifulSoup(response_deep.content,features=\"lxml\")\n",
    "    text1=sub_soup.findAll(\"div\", {\"class\": \"description__text description__text--rich\"})\n",
    "\n",
    "    for s in text1:\n",
    "        description = s.text\n",
    "        description_df = description_df.append({'Description': description}, ignore_index=True)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_prj-SRynVlFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34304ceff4189be5ec3888addaf2a860e88df2f436b7958182f0d19632a0f568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
